---
title: "Automatizaci√≥n de Series de Datos de Empleo (S√°banas)"
format: typst
lang: es
---

# Automatizaci√≥n de Series de Datos de Empleo IMSS

## Objetivo del Proyecto

Este proyecto tiene como objetivo automatizar la generaci√≥n y actualizaci√≥n de las series de datos conocidas como "S√°banas" del IMSS. El sistema permite actualizar las series de tiempo de empleo de manera eficiente y automatizada.

## Estado Actual del Proyecto

### ‚úÖ Completado
- Automatizaci√≥n de desagregaciones de datos
- Flujo de trabajo con `targets` funcional
- Proceso de actualizaci√≥n de series mediante `tar_make()`

### üîÑ Pendiente
- Generaci√≥n de res√∫menes estad√≠sticos (como los de las s√°banas actuales)
- Deployment de la aplicaci√≥n Shiny en servidor de producci√≥n
- Automatizaci√≥n completa del pipeline mensual
- Implementaci√≥n de pruebas de validaci√≥n autom√°tica

## Definiciones y Metodolog√≠a

### Conceptos Principales

#### Series de Tiempo Generadas
1. **Asegurados Trabajadores**
   - **Por Modalidad**: 11 modalidades del r√©gimen obligatorio (10, 11, 12, 13, 14, 17, 32, 33, 34, 38, 97)
   - **Por Sector Econ√≥mico**: 21 divisiones de actividad econ√≥mica seg√∫n clasificaci√≥n IMSS
   - **Universo**: Trabajadores con relaci√≥n laboral vigente al cierre del mes

2. **Patrones (Empleadores)**
   - **Por Modalidad**: 6 modalidades principales con al menos un trabajador activo
   - **Por Rango de Trabajadores**: 6 categor√≠as por tama√±o de empresa
     - 1 trabajador
     - 2-5 trabajadores  
     - 6-10 trabajadores
     - 11-50 trabajadores
     - 51-500 trabajadores
     - M√°s de 500 trabajadores

3. **Salario Promedio**
   - **Por Modalidad**: Salario base de cotizaci√≥n promedio ponderado por n√∫mero de asegurados
   - **C√°lculo**: Media ponderada del salario de cotizaci√≥n mensual
   - **Moneda**: Pesos mexicanos corrientes

#### Desagregaci√≥n Geogr√°fica
- **Nacional (c√≥digo 99)**: Agregado de todas las delegaciones
- **Delegacional (c√≥digos 01-35)**: 35 delegaciones estatales del IMSS
- **Subdelegacional (c√≥digos 001-999)**: ~300 subdelegaciones operativas

#### Modalidades de Aseguramiento
- **Modalidad 10**: Trabajadores permanentes urbanos
- **Modalidad 11**: Trabajadores eventuales urbanos  
- **Modalidad 12**: Trabajadores permanentes del campo
- **Modalidad 13**: Trabajadores eventuales del campo
- **Modalidad 14**: Trabajadores eventuales de la industria azucarera
- **Modalidad 17**: Reversi√≥n de cuotas
- **Modalidad 32**: Trabajadores al servicio de gobiernos estatales  
- **Modalidad 33**: Trabajadores al servicio de gobiernos municipales
- **Modalidad 34**: Trabajadores de universidades p√∫blicas
- **Modalidad 38**: Trabajadores dom√©sticos
- **Modalidad 97**: Trabajadores no asalariados

### Metodolog√≠a de Procesamiento

#### Fuente de Datos Primaria
**Archivo Base**: `pafinalmes*` (Padr√≥n de Afiliaci√≥n Final Mensual)
- **Frecuencia**: Mensual, disponible ~5 d√≠as h√°biles despu√©s del cierre
- **Cobertura**: Universo completo de trabajadores registrados ante el IMSS
- **Registros**: ~20 millones de trabajadores activos por mes
- **Variables clave**: NSS, delegaci√≥n, subdelegaci√≥n, modalidad, sector, salario, empresa

#### Proceso de Agregaci√≥n
```sql
-- Pseudoc√≥digo del proceso de agregaci√≥n en SAS
SELECT 
    ta,                          -- Tipo de alta (1=vigente)
    div_final,                   -- Divisi√≥n econ√≥mica
    size_cierre,                 -- Rango de tama√±o de empresa
    cve_del_final,               -- Clave delegaci√≥n
    cve_subdel_final,            -- Clave subdelegaci√≥n  
    mod,                         -- Modalidad
    tipotrc,                     -- Tipo trabajador
    COUNT(nss) as asegurados,    -- Conteo de trabajadores √∫nicos
    MEAN(sal_cierre) as salario, -- Salario promedio
    SUM(empresas3) as patrones   -- Conteo de patrones √∫nicos
FROM pafinalmes_YYYYMM
WHERE aseg_cierre = 1            -- Solo asegurados vigentes
  AND aseg = 1                   -- Con alta definitiva
GROUP BY ta, cve_del_final, cve_subdel_final, mod, tipotrc, div_final, size_cierre;
```

#### Validaciones Implementadas
1. **Consistencia temporal**: Verificaci√≥n de continuidad en series
2. **Totales de control**: Validaci√≥n contra agregados oficiales
3. **Rangos esperados**: Detecci√≥n de valores at√≠picos autom√°tica
4. **Integridad referencial**: Validaci√≥n de c√≥digos contra diccionarios



## Flujo de Trabajo Principal

Para actualizar las series de datos, siga estos pasos:

1. **Ejecutar el c√≥digo SAS**: `fetch_employment.sas`
2. **Ejecutar el proceso de targets**: `targets::tar_make()` en R

Este flujo de trabajo actualiza autom√°ticamente todas las series de tiempo exportadas a trav√©s de la aplicaci√≥n Shiny.

## Estructura de Archivos

### Entradas (Inputs)

#### Datos Principales
- **`fetch_employment.SAS`**: Script SAS que extrae datos del archivo m√°s reciente `pafinalmes*` desde la base de datos corporativa del IMSS
- **S√°banas tradicionales (Excel)**: Archivos hist√≥ricos ubicados en `data/raw/SABANAS/` organizados por:
  - **DELEGACIONES/**: Datos agregados a nivel delegacional
  - **SUBDELEGACIONES/**: Datos desagregados a nivel subdelegacional
  - Categor√≠as: `ASEGURADOS Y PATRONES/`, `METAS, RECAUDACI√ìN Y COBRANZA/`, `POBLACIONES/`

#### Diccionarios y Cat√°logos
- **`dictionaries/delegaciones.xlsx`**: Mapeo de claves y nombres de delegaciones y subdelegaciones
- **`data/dictionary.xlsx`**: Diccionario de c√≥digos de modalidad, sectores econ√≥micos y rangos
- **`data/catalogue.xlsx`**: Cat√°logo autom√°tico de archivos Excel disponibles
- **`_keys/imss_pwd.txt`**: Credenciales para acceso a datos (archivo seguro)

### Salidas (Outputs)

#### Datos Procesados
- **`data/sheets/sheets_data.parquet/`**: Base de datos principal en formato Parquet particionada por:
  - `book_name`: Tipo de serie (ej. "Asegurados trabajadores por modalidad")
  - `sheet_name`: Desagregaci√≥n espec√≠fica (ej. "Modalidad 10", "Sector Industrial")
- **`temp1.duckdb`**: Base de datos temporal para consultas r√°pidas
- **`data/sheets.feather` y `data/sheets.RData`**: Formatos alternativos de almacenamiento

#### Aplicaci√≥n Web
- **`shiny/app.R`**: Aplicaci√≥n Shiny interactiva para:
  - Visualizaci√≥n de series de tiempo con gr√°ficos interactivos
  - Filtrado por nivel geogr√°fico (Nacional, Delegacional, Subdelegacional)
  - Selecci√≥n de entidades m√∫ltiples con b√∫squeda
  - Exportaci√≥n a CSV y Excel en formato ancho o largo
  - Agregaci√≥n autom√°tica de selecciones m√∫ltiples

#### Reportes
- **`README.html`**: Documentaci√≥n renderizada del proyecto
- **`notebooks/review.qmd`**: Cuaderno Quarto para an√°lisis y revisi√≥n de datos

### C√≥digo Principal

#### Pipeline de Datos (`targets`)
- **`_targets.R`**: Orquestador principal que define el flujo de trabajo automatizado:
  - `raw_data_path`: Ubicaci√≥n de datos hist√≥ricos
  - `historical_sheets_data`: Lectura de s√°banas Excel hist√≥ricas
  - `fresh_data`: Extracci√≥n de datos frescos desde SAS
  - `current_month`: C√°lculo autom√°tico del mes a procesar
  - `dictionary`: Carga de diccionarios de c√≥digos
  - `fresh_data_cleaned`: Limpieza y transformaci√≥n de datos frescos
  - `new_sheets`: Generaci√≥n de nuevas series de tiempo
  - `updated_sheets`: Combinaci√≥n con datos hist√≥ricos
  - `saved_sheets_data`: Almacenamiento final en formato Parquet

#### Funciones Principales (`R/`)
- **`functions.R`**: Funciones centrales del procesamiento:
  - `pull_fresh_data()`: Conecta v√≠a SFTP y extrae datos SAS m√°s recientes
  - `clean_fresh_data()`: Normaliza c√≥digos de modalidad y limpia variables
  - `make_new_sheets()`: Genera 5 tipos de series de tiempo:
    - Asegurados por modalidad y sector econ√≥mico
    - Patrones por modalidad y rango de trabajadores  
    - Salario promedio por modalidad
  - `update_sheets()`: Valida y combina datos nuevos con hist√≥ricos
  - `save_updated_sheets()`: Guarda en formato Parquet particionado

- **`read_sheets.R`**: Procesamiento de s√°banas Excel hist√≥ricas:
  - `read_content()`: Extrae √≠ndices de contenido de archivos Excel
  - `read_sheet()`: Lee hojas individuales y pivotea fechas
  - `read_sheets()`: Funci√≥n principal que procesa todos los archivos Excel
  - `read_delegaciones_dictionary()`: Carga diccionario geogr√°fico

#### M√≥dulos Auxiliares
- **`R-other/reset_sheets.R`**: Reinicializaci√≥n completa desde s√°banas hist√≥ricas
- **`SAS/fetch_employment.SAS`**: Extracci√≥n automatizada de datos corporativos:
  - Identifica archivo m√°s reciente `pafinalmes*`
  - Agrega datos por delegaci√≥n, modalidad, sector y tama√±o de empresa
  - Calcula conteos de asegurados, patrones y salarios promedio
  - Exporta a `employment_counts.sas7bdat`

#### Aplicaci√≥n Web (`shiny/`)
- **`app.R`**: Aplicaci√≥n modular con:
  - M√≥dulos reutilizables por tipo de serie
  - Interfaz reactiva con filtros geogr√°ficos y conceptuales
  - Visualizaci√≥n con Plotly interactivo
  - Exportaci√≥n flexible en m√∫ltiples formatos

## Uso del Sistema

### Actualizaci√≥n Regular (Mensual)

#### Paso 1: Extracci√≥n de Datos SAS
```sas
/* Ejecutar en SAS Enterprise Guide o SAS Studio */
%include "SAS/fetch_employment.SAS";
```
Este script:
- Identifica autom√°ticamente el archivo m√°s reciente `pafinalmes*`
- Procesa aproximadamente 20 millones de registros de trabajadores
- Genera agregaciones por delegaci√≥n, modalidad, sector econ√≥mico y tama√±o de empresa
- Guarda resultados en `employment_counts.sas7bdat`

#### Paso 2: Procesamiento en R
```r
# Cargar el pipeline de targets
library(targets)

# Ejecutar todo el pipeline de actualizaci√≥n
tar_make()

# Verificar el estado del pipeline
tar_visnetwork()

# Ver progreso en tiempo real
tar_progress()
```

El pipeline procesar√° autom√°ticamente:
1. **Datos frescos**: Conexi√≥n SFTP para obtener `employment_counts.sas7bdat`
2. **Limpieza**: Normalizaci√≥n de c√≥digos y fechas
3. **Generaci√≥n**: Creaci√≥n de 5 tipos de series de tiempo diferentes
4. **Validaci√≥n**: Verificaci√≥n de consistencia con datos hist√≥ricos
5. **Almacenamiento**: Guardado en formato Parquet optimizado

### Visualizaci√≥n y Exportaci√≥n

#### Aplicaci√≥n Shiny Local
```r
# Ejecutar la aplicaci√≥n web
shiny::runApp("shiny/app.R")
```

La aplicaci√≥n permite:
- **Filtrado interactivo**: Por nivel geogr√°fico, entidades y conceptos
- **Visualizaci√≥n**: Gr√°ficos de l√≠neas interactivos con Plotly
- **Exportaci√≥n**: Descarga en CSV o Excel, formato ancho o largo
- **Agregaci√≥n**: Suma autom√°tica de m√∫ltiples entidades seleccionadas

#### Acceso Program√°tico
```r
# Cargar datos directamente
library(arrow)
series <- open_dataset("data/sheets/sheets_data.parquet")

# Ejemplo: Asegurados por modalidad a nivel nacional
nacional <- series |>
  filter(
    series == "Asegurados",
    disaggregation == "Modalidad",
    clave_delegacion == 99,
    is.na(clave_subdelegacion)
  ) |>
  collect()

# Ejemplo: Exportar serie espec√≠fica
series |>
  filter(
    series == "Patrones",
    level == "Delegaci√≥n",
    date >= as.Date("2020-01-01")
  ) |>
  collect() |>
  write_csv("patrones_delegacional.csv")
```

### Reinicializaci√≥n Completa

‚ö†Ô∏è **Solo en casos excepcionales**: Cuando sea necesario reestablecer completamente las series desde las s√°banas tradicionales Excel:

```r
# PRECAUCI√ìN: Esto sobrescribir√° todos los datos automatizados
source("R-other/reset_sheets.R")
```

**Cu√°ndo usar reinicializaci√≥n**:
- Cambios en la estructura de datos hist√≥ricos
- Correcciones masivas en s√°banas Excel originales  
- Migraci√≥n o restauraci√≥n del sistema
- Cambios en diccionarios de c√≥digos

### Monitoreo y Mantenimiento

#### Verificaci√≥n de Datos
```r
# Verificar √∫ltima actualizaci√≥n
tar_meta(fields = timestamp) |> 
  arrange(desc(timestamp))

# Revisar errores en el pipeline
tar_meta(fields = c(name, error)) |>
  filter(!is.na(error))

# Estad√≠sticas de la base de datos
series |> count() |> collect()
series |> summarise(
  min_date = min(date),
  max_date = max(date),
  n_series = n_distinct(paste(series, disaggregation))
) |> collect()
```

#### Respaldo de Datos
```r
# Crear respaldo manual
file.copy(
  "data/sheets/sheets_data.parquet",
  paste0("backup_", Sys.Date(), ".parquet"),
  recursive = TRUE
)
```

**Nota**: El sistema est√° dise√±ado para actualizaciones incrementales mensuales. El flujo normal (`tar_make()`) solo procesa datos nuevos, manteniendo la integridad hist√≥rica y optimizando el rendimiento.

## Arquitectura T√©cnica

### Flujo de Datos

```mermaid
graph TD
    A[Base Corporativa IMSS] -->|SAS fetch_employment| B[employment_counts.sas7bdat]
    C[S√°banas Excel Hist√≥ricas] -->|R read_sheets| D[historical_sheets_data]
    B -->|SFTP pull_fresh_data| E[fresh_data]
    E -->|clean_fresh_data| F[fresh_data_cleaned]
    F -->|make_new_sheets| G[new_sheets]
    D -->|update_sheets| H[updated_sheets]
    G --> H
    H -->|save_updated_sheets| I[sheets_data.parquet]
    I --> J[Aplicaci√≥n Shiny]
    I --> K[Exportaciones CSV/Excel]
```

### Tecnolog√≠as Utilizadas

#### Almacenamiento y Procesamiento
- **Apache Parquet**: Formato columnar optimizado para an√°lisis
- **Apache Arrow**: Interfaz de acceso a datos de alto rendimiento
- **DuckDB**: Motor de consultas SQL embebido para an√°lisis
- **R Targets**: Orquestaci√≥n de pipelines de datos reproducibles
- **renv**: Gesti√≥n de entornos y dependencias de R

#### Conectividad y Extracci√≥n
- **SAS/CONNECT**: Acceso a bases de datos corporativas SAS
- **SFTP**: Transferencia segura de archivos entre sistemas
- **haven**: Lectura de archivos SAS desde R
- **readxl**: Procesamiento de archivos Excel complejos

#### Visualizaci√≥n y Aplicaciones
- **Shiny**: Framework web reactivo para R
- **Plotly**: Gr√°ficos interactivos y exportables
- **DT**: Tablas interactivas con b√∫squeda y filtrado
- **Quarto**: Documentaci√≥n cient√≠fica reproducible

### Especificaciones de Datos

#### Dimensiones Principales
- **Temporal**: Series mensuales desde enero 2019 hasta presente
- **Geogr√°fica**: 3 niveles (Nacional, 35 Delegaciones, ~300 Subdelegaciones)
- **Conceptual**: 5 tipos de series principales:
  1. **Asegurados**: Por modalidad (11 categor√≠as) y sector econ√≥mico (21 divisiones)
  2. **Patrones**: Por modalidad (6 categor√≠as) y rango de trabajadores (6 rangos)
  3. **Salario**: Promedio ponderado por modalidad

#### Estructura de la Base de Datos
```sql
-- Esquema principal sheets_data.parquet
CREATE TABLE sheets_data (
    book_id INTEGER,           -- ID del libro/categor√≠a
    sheet_id INTEGER,          -- ID de la hoja/serie espec√≠fica  
    book_name STRING,          -- Nombre del libro (ej. "Asegurados trabajadores por modalidad")
    sheet_name STRING,         -- Nombre de la serie (ej. "Modalidad 10")
    level STRING,              -- Nivel geogr√°fico: "Nacional", "Delegaci√≥n", "Subdelegaci√≥n"
    date DATE,                 -- Fecha mensual (primer d√≠a del mes)
    clave_delegacion INTEGER,  -- C√≥digo de delegaci√≥n (01-35, 99=Nacional)
    clave_subdelegacion INTEGER, -- C√≥digo de subdelegaci√≥n (01-999, 99=Total delegacional)
    delegacion STRING,         -- Nombre de la delegaci√≥n
    subdelegacion STRING,      -- Nombre de la subdelegaci√≥n
    series STRING,             -- Tipo de serie: "Asegurados", "Patrones", "Salario"
    disaggregation STRING,     -- Tipo de desagregaci√≥n: "Modalidad", "Sector econ√≥mico", etc.
    value DOUBLE              -- Valor num√©rico de la serie
);
```

#### Particionamiento
Los datos se almacenan particionados por `book_name` y `sheet_name` para optimizar consultas:
```
data/sheets/sheets_data.parquet/
‚îú‚îÄ‚îÄ book_name=Asegurados trabajadores por modalidad/
‚îÇ   ‚îú‚îÄ‚îÄ sheet_name=Modalidad 10/
‚îÇ   ‚îú‚îÄ‚îÄ sheet_name=Modalidad 11/
‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îú‚îÄ‚îÄ book_name=Patrones por modalidad/
‚îî‚îÄ‚îÄ ...
```

### Rendimiento y Escalabilidad

#### Optimizaciones Implementadas
- **Lectura incremental**: Solo procesa meses nuevos, no datos hist√≥ricos
- **Almacenamiento columnar**: Parquet reduce tama√±o ~80% vs CSV
- **Particionamiento inteligente**: Consultas filtran solo particiones relevantes
- **Conexi√≥n lazy**: Arrow abre datasets sin cargar en memoria
- **Compresi√≥n SNAPPY**: Balance √≥ptimo entre compresi√≥n y velocidad


## Pr√≥ximos Pasos

### Desarrollo Prioritario
1. **Generaci√≥n autom√°tica de res√∫menes estad√≠sticos**
   - C√°lculos de variaciones mensuales y anuales
   - Detecci√≥n autom√°tica de anomal√≠as en series
   - Reportes ejecutivos automatizados

2. **Deployment en producci√≥n**
   - Configuraci√≥n de servidor Shiny Pro/Connect
   - Automatizaci√≥n de actualizaciones mensuales v√≠a cron
   - Monitoreo y alertas de fallos en pipeline

3. **Validaci√≥n y calidad de datos**
   - Pruebas unitarias para funciones cr√≠ticas
   - Validaci√≥n cruzada con s√°banas oficiales
   - Alertas autom√°ticas por inconsistencias

### Mejoras Futuras
4. **Interfaz de usuario mejorada**
   - Dashboard ejecutivo con KPIs principales
   - Comparaciones autom√°ticas per√≠odo anterior

5. **Integraci√≥n con otros sistemas**
   - API REST para consultas externas
   - Conexi√≥n directa con Business Intelligence
   - Sincronizaci√≥n con repositorios oficiales

6. **An√°lisis avanzado**
   - Modelos de forecasting autom√°tico
   - Detecci√≥n de patrones estacionales
   - An√°lisis de correlaciones inter-series
